---
title: "Machine Learning Project"
author: "Andres Azqueta"
date: "Friday, October 23, 2015"
output: pdf_document
---
## Summary 
In this work I will analyze the data given by this assignment and by conducting a machine learning process in the training set I will estimate the exercise category in the test set. In order to do so I first describe what I see in the data (control variables and dependent variable as well as missing samples) and I filter it given the high number of missing variables and near zero variance. Moreover, I create a partition to start the machine learning process. In this partition 70 percent of the data will be categorize as the training set while the remaining will be the testing set. Once the data is ready for further process, I apply a Random Forest technique to develop an algorithm that can categorize the data into the different class category of the dependent variable. The performance of this algorithm is sound and accurate in both, the training and the testing data. 

## Data Description

```{r}
library(gdata)
Test <- read.table("pml-testing.csv", header=T,sep=";")
Train <- read.table("pml-training.csv", header=T,sep=";")
head(Test)
head(Train)
```
In this section I create a partition of the data into training and testing set and moreover I remove the missing variables and the near zero variance. Recall that the near zero variance variables are those variables with really little variability which will likely not be a good predictors, which motivates removing them. 

```{r}
library(caret)
library(ggplot2)
library(lattice)
library(kernlab)
library(randomForest)
inTrain <- createDataPartition(Train$classe,p=.7,list=FALSE)
training = Train[inTrain,]
testing = Train[-inTrain,]
set.seed(143759)
```

With this partition 70% of my data from the “Train” data set is under the “training” object while the remaining is under the “testing” object.  I have set the seed to be 143759 which is totally random. 
I will now proceed to exclude the near zero variance features from the training set.  

```{r}
nzvcol <- nearZeroVar(training)
training <- training[, -nzvcol]
```
Furthermore, and given the high amount of missing variables (NA) that we can observe in the data by typing “Test” or “Train” it makes sense the get rid of those variables with more that 50 percent of the observations missing: 


```{r}
cntlength <- sapply(training, function(x) {
sum(!(is.na(x) | x == ""))
})
nullcol <- names(cntlength[cntlength < 0.5 * length(training$classe)])
descriptcol <- c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", 
"cvtd_timestamp", "new_window", "num_window")
excludecols <- c(descriptcol, nullcol)
training <- training[, !names(training) %in% excludecols]
```

We now have a clean data, where those variables with more that 50% observations missing are not longer in our sample set and neither those with near zero variance. 

## Random Forest and Model validation: 

Since the variable that we want to predict (class) is composed by 5 different types (A, B, C, D & E) it makes sense to use a Random Forest Process. This process operates by constructing a multitude of decision trees and outputting the class in individual branches. In other words, the uncorrelated trees are composed with specific algorithms with high predictor power for each class. In this specific example, I construct 15 specific trees (random number) or partitions that help determine what observations correspond to each category. 
One way to start with Random Forest is to create a modFit function:

```{r}
modFit <- train(training$classe ~.,method="rf",prox=TRUE)
print(modFit)
```

With this commands I have create the model composed of 13737 samples, 52 predictor and 5 classes. By setting prox=True, the function produces a little more extra information. Nevertheless to use a rfModel function might be more helpful since the results are going to be easier to interpret it. In the following command I set the rfModel function with 15 different trees. 

```{r}
rfModel <- randomForest(classe ~ ., data = training, importance = TRUE, ntrees = 15)
```

The next step is to show how well this algorithm predicts the data in which is built from.

```{r}
ptraining <- predict(rfModel, training)
print(confusionMatrix(ptraining, training$classe))
```

The accuracy of 1, the constrained confident interval and the close to cero P-value tells us that the prediction power of this algorithm is really strong and highly significant. Nevertheless, and in order to test for over fitting, we now need to apply it to the “testing” set. 

As expected, the accuracy in this set is slightly lower (0.99) but nevertheless really powerful and accurate (look at P-values and confident interval).  
Once we have validate the machine learning algorithm given by the Random Forest exercise in partitioned sets from the “Train” data, it is time to predict the categories of those observation from the “Test” data set. 

```{r}
ptest <- predict(rfModel, Test)
ptest
```



